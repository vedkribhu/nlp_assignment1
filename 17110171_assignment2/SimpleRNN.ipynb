{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "eYZtVz98G-x6",
    "outputId": "c35291c0-a89f-45f7-8d1b-f45f3ab405e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /gdrive\n",
      "/gdrive/My Drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive/My Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_OaT0K-Gu-m"
   },
   "outputs": [],
   "source": [
    "text = open('at.txt', 'r').read()\n",
    "text = text.lower()\n",
    "train_text = text[:int(len(text)*0.8)]\n",
    "test_text = text[int(len(text)*0.8)+1:]\n",
    "# sent_tokenize_list = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rkhN-Pr8qLyr",
    "outputId": "45c1e110-e1bc-499a-9ac8-65ce46145156"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, SimpleRNN\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "3Mr1maeLq7Ac",
    "outputId": "4a849268-38d3-4905-afc7-4f05896f9a7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 64\n",
      "nb sequences: 238988\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "#I have used Keras official github example of LSTM as reference for this part of assignment.\n",
    "#https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py\n",
    "chars = sorted(list(set(train_text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(train_text) - maxlen, step):\n",
    "    sentences.append(train_text[i: i + maxlen])\n",
    "    next_chars.append(train_text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "0zD7Vd5Iq-om",
    "outputId": "f5ef4752-ac54-48f4-ab6c-f87ab37974fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C9F6dzOqsX1t"
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "VwjOYYv4sbUa",
    "outputId": "f254eb13-1d48-4934-f38d-3408e1a65f96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/10\n",
      "238988/238988 [==============================] - 64s 268us/step - loss: 2.2610\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ut a lot of people would say \"he’s not t\"\n",
      "ut a lot of people would say \"he’s not the pere the prople in the prople the proplestore poon the prople and in the prople and in wall the prople and the precound you know, the wall the prople that of oul the prople and the precount out ingo and the prople the prople in the wall and the prople and the prople and in the wore the poon the prople and the prople and the prople of the prople and the prople and the prople and in wing to the p\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ut a lot of people would say \"he’s not t\"\n",
      "ut a lot of people would say \"he’s not that and of mure andonedind in the pont of of oug to our and becanee they have reat of ofchone hes ine wear arad and now that ous of the prople therere and the poon thes inte and the have we cous.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "and and an, are they wall and hat what hith and beo ase way that that of thit dot’t toun they of got ande and bat ing on\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ut a lot of people would say \"he’s not t\"\n",
      "ut a lot of people would say \"he’s not toomesoudvery julver o couley thor ah w eree tres pacperotcariseay.ry hackeru\n",
      "ho hanu. iome.\n",
      "\n",
      "\n",
      " mers allt.io dealt outre primi atamh, youn. ialy bastewow arifalrearf,oy,eand, ever abeet oolas.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "were hane arest oald if theve – chas yom vealdesa noti ason aawerdined.\n",
      "\"\n",
      "ondy. thay of csmos anem anow ghing ara orant, ave thacksone. poenlatduca, and orl hat ofloca. batey ave batu tom dehaisy afd, o\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ut a lot of people would say \"he’s not t\"\n",
      "ut a lot of people would say \"he’s not thateryeca. esd wa lthey.\n",
      "ande thay, it? in no ctuich\"\n",
      "\n",
      "theha onte co warlefirsaciyet callyodod’r waut anereth towi t sore ople tyetedous, itmctane, youm? yourfllki ilis, hemhave so bot nemsienaw, the $%xmzelint, hace raill. ande thom thste thaddintase.di aspthizceonst wcoundouge wame it allicau ingo, now that’se bpeligeroag.\n",
      "is inaign, ot. ther guteabs you thois, oul ons joplore loike\n",
      "\n",
      "ndty us’ne \n",
      "Epoch 2/10\n",
      "238988/238988 [==============================] - 55s 231us/step - loss: 1.9290\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" the way. i’ve been here many times. gre\"\n",
      " the way. i’ve been here many times. great and the wall the werter the prople and the sald and here and the warl the wall the sore the people and the wall the wall the poont of the perice and the wall and the sald and the perican of the perster of the sald and it’s and the wart to going to be the prople the prople the prople fore the pericalle sore then the perice and the wart the wall the warl the samp of the wall and the ward the pare\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" the way. i’ve been here many times. gre\"\n",
      " the way. i’ve been here many times. grent that have to nald reand forsand country the predon the going to bald and is and i can’s and the sead an cand and the wart of thecr and and hemending ou doon are the samp of the remary the pact ce peoplechers if the warr thened because poong tore soreive count if roon any – inge to got the war hig there the bagr then the s aver the umppoted dorean thoup hacknow, they’re beange camp.\n",
      "i wand thes \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" the way. i’ve been here many times. gre\"\n",
      " the way. i’ve been here many times. gre then burseruce. weres you kney werfeat helentexaflatior anow.\"thendy rofse tham zombed forbe and ill mong mo filysoinglanof ghowe arescapdlelicact and tof hak tomatsrin cfople.\n",
      "sheysand. all byit, they’revelltantemustorag tore. amprelingoll thall hage arieg thenus wored veryburicesocact way than wof lit save theny. bucking hay over bunty spaningingcans. e pobid walls ow merten wornde coupro. he w\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" the way. i’ve been here many times. gre\"\n",
      " the way. i’ve been here many times. gres bucc. becnule, jobrdically ugr meer, reu. ?0x paxaner angrspony fergme hablicuppongrevelyorlis sos aboustw., here ceuppebat ocome percicw reonf cernie’ve a\n",
      "o, neknow, irmelly merus ppreallave loceatindon wyoce of can’tr and wercan. sy 50ghingn. cfonswo asn tore, berseseo thesm prealchersight ome t0 tfxceenbig t?ny.\n",
      ", pompact tol. you dopllty o2d -pancer breduclen’r bableck cerang.e therc, i sobl\n",
      "Epoch 3/10\n",
      "238988/238988 [==============================] - 53s 221us/step - loss: 1.7952\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ut. the only difference is there’s nothi\"\n",
      "ut. the only difference is there’s nothing it the was sount. it’s the wart to be a lor it the that say they don’t want to be a very all of the staters and it the really of the statisesting it and it the really siment of the say the wall of the wally sime it the riget it would have the right it the wast to be the wall that say the stare some of the was sourt. it’s not the prople that say they’re going to be the was some of the sald and i\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ut. the only difference is there’s nothi\"\n",
      "ut. the only difference is there’s nothing he way i know the proble sore tiles and it really will the walle say for the ward they was so but we have thes look. i going to got to have to here got to wis souple the great icteriont it ur bof go think there with the wall, it’s the stally or that it or momenting ain the prople the want they don’t keap neare sites. it? and they’re gring to bo thes going to have to but they dedore. i many peop\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ut. the only difference is there’s nothi\"\n",
      "ut. the only difference is there’s nothing us. illeiny rondilokina greevery reot's ir. se’s, hererebasinite.sere that. an’re thask you.\n",
      "\n",
      "\n",
      "\n",
      "torecm of everybody cond.\n",
      "y ortbalny.\n",
      "\n",
      "\n",
      "snot it of oul that she fon aplian for,ade.\n",
      "\n",
      "and myse, whare whus ore wis sale ie upit. it’s eesare, they was p onembat of mone, they. i winls pintshtits, you’s carelined ildes. i menring faid, of gee arcust grtim— to chastal that we’re bery hivering ebed i’ve \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ut. the only difference is there’s nothi\"\n",
      "ut. the only difference is there’s nothing mives cempanien of menhtons rate ofy redmong.y bech, rich’s ut meyhit onve. bus i vidntasing l ont rfoeforel. thuy, i caid tiknnrthant, 30, julp.\n",
      "ith\" lads \n",
      "any reduy ntery you% nextry it the arioumesiint anfonidaling. see to dewald in reaiclion.. $- makn. tous, ofas thould. edowist if and, rest filgrymartor. wo ardome.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tsery of the. we’re dong to no goidg maqreatedlef fow yid salffre it\n",
      "Epoch 4/10\n",
      "238988/238988 [==============================] - 53s 223us/step - loss: 1.7070\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"s going on, but they used the excuse of \"\n",
      "s going on, but they used the excuse of the proned that we have the people that we have to the don’t know what they don’t don’t don’t don’t don’t don’t thing to the way a because they don’t don’t don’t don’t don’t don’t don’t don’t don’t don’t have then we not the dond they want to the going to be the prople that we have to do nemore then they don’t know what i mane then we have to the don’t don’t don’t don’t don’t know what we can’t do\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"s going on, but they used the excuse of \"\n",
      "s going on, but they used the excuse of or mine then me thing they want thet great don’t don’t don’t de in that people that be and it to ne that the word that’s seating that we can the werd that peond that we don’t done. they want the people thank they have to dond thank you the got companien the polle that we have to te to de for the mary don’t ange. they sich spend the that that want then’s sean, then come people then we have so nemen\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"s going on, but they used the excuse of \"\n",
      "s going on, but they used the excuse of sereb.\n",
      "\n",
      "\n",
      "on there. omes. i going take pan. be a leaving wo hhes hore se’r 2nom? ou, we’ve know shet’men veny. they foren wene that.\n",
      "\n",
      "\n",
      "and eady’s minde remple. youw whote tlly. they theru maybstith they donge dester lyon we nogrtut thout whoching to nothus countrybtur mertilt and sestede seure thruen tout us vit. thimp hippen theer essilk, 18 nor a fom mo, a for me iempinely habe fexteriprys thath \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"s going on, but they used the excuse of \"\n",
      "s going on, but they used the excuse of amuricimess, he woned borken.\n",
      "a lowe thise theme heth hame.\n",
      "i’m aints, you’ll s, – whee hevety sor12, kere targend andenyss,.\n",
      "they have a meen heve you fil2s, htrita cend. years – and lome bigh whon. sait..\n",
      "act’s tele aried.\n",
      "to not lout? wanting them oh we’ve compers thenesply disgly som. vicy evoress irees to ovich if nexow, then we denter bringn tor for tsme ho foringusp hith prast. bo the gette\n",
      "Epoch 5/10\n",
      "238988/238988 [==============================] - 53s 223us/step - loss: 1.6421\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"what we want to do?\n",
      "i’ll bet you that if\"\n",
      "what we want to do?\n",
      "i’ll bet you that if i said, \"what and they do it say it to be the people that i have the people the stored the prople the erough and they we have the erough of the people the people the erough of the prople that i want to be the people and they wante the people the problem. and they have the erome that i to do the one of the people the people the people the because they go the erough of the people the people that i \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"what we want to do?\n",
      "i’ll bet you that if\"\n",
      "what we want to do?\n",
      "i’ll bet you that if these, so munding the erough the areated he diding you have the sell and they would you have the eroment and we’re going to be sto the eronged and the secalserust or the berses the people the erouth way or mines. he sears an the seren be the way the are then you know of the people the people – the are theney has a cante froming in the erade a dingerent of the people the reanted the sester it sand\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"what we want to do?\n",
      "i’ll bet you that if\"\n",
      "what we want to do?\n",
      "i’ll bet you that if i wawrad, ok at ughaca me.\n",
      "\n",
      "\n",
      "f artump out elees, very of these people untrable atway. i’ll geerrectils, we have to for all ever the lit. eves to to in oun lorsell., you decairy, and the chinking arcessens, i’m are frimmerrpestu, i mane, i’ve gether in treme – they gredt folle. they we thay same and tigged has in\n",
      "\n",
      "\n",
      "ant i fount anf there.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i’m going to all over whempleved ever so fors to it a \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"what we want to do?\n",
      "i’ll bet you that if\"\n",
      "what we want to do?\n",
      "i’ll bet you that if alkayp cessare, te bo net righl? siad... he uatest. we’re now? s? pacter aillive couttrceed?, howeak, hu. dega onth akno, chsibec...rimd of just caminalders eve yous respebods to sen the saw,, if remigse i wceriatwithe? do enos we trung. it’s a mullio seftore.\n",
      "\n",
      "\n",
      "remporiandernesthen you goiovery, sazies. the e’sl selicla, a frimbirive yo furdigs. and i’m, thguts, yur. i’sl la.milking in the 1'ml t\n",
      "Epoch 6/10\n",
      "238988/238988 [==============================] - 53s 221us/step - loss: 1.5922\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"nd when we unify, there’s nobody, nobody\"\n",
      "nd when we unify, there’s nobody, nobody the great and i said the grout the going to be the going to be the going to be the going to be the grout the going to be the going to be the going to do the going to be the going to be the going to be the going to be the going to be the going to be the going to be the going to be the going to do the going to be the going to do the going to be the going to do the going to be the going to the going\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"nd when we unify, there’s nobody, nobody\"\n",
      "nd when we unify, there’s nobody, nobody say i’m very makion. they don’t lote. i want to the grout the was a saiding. and i gatt the geate money would be the people a sight now, i love and i said would controns it the got a wert on the good and i said, \"he with the way, \"we have then the going to be ser in the going to tell you he was a because i’m hay. we don’t lost it in the got in the got the gotard. and i to the would be the state. \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"nd when we unify, there’s nobody, nobody\"\n",
      "nd when we unify, there’s nobody, nobody the very hames ? could do ip love vorsth comending. i’m becatiean waster, whing they doss fomangs it thingnsatell.\" it’s bad now to be wall are then’men.\n",
      "\n",
      "\n",
      ".\n",
      "we had a bboutien people jow aw and. and i me.is, theter what’s notcrmuge. it’r mafiaterijusing bastite by a you do that.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i\n",
      "lok ol thingry great robusee to our counting, to say. you know what’s ambaing of puoper on bowan en the getals. t\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"nd when we unify, there’s nobody, nobody\"\n",
      "nd when we unify, there’s nobody, nobody leve, has af oh youre. wa arom; i towirt, the chut. leme the seod us the bout pheteridn’t tollen’t like people hea2, much imcing a oul polatiat jubacal money. the rables cont’s 1$9 aing od bo thomy of thonew whating.\n",
      "but moks do the real\n",
      " henribut bjje 000 an acy them – focked ibat elfwice' fatefre \"he. woll of the geanaw oles who hand we’re mano? yor thong wo harl wisa ligmyity go from i atd any\n",
      "Epoch 7/10\n",
      "238988/238988 [==============================] - 53s 222us/step - loss: 1.5525\n",
      "\n",
      "----- Generating text after Epoch: 6\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"shonest, the press goes – headlines the \"\n",
      "shonest, the press goes – headlines the right not in the way there is so the way the way the right that i was a lot of the itar and they are many so many and they are many so mind the way the eadion and they star stars the right not in the world back. they say they the the the the the the the the the right to be a lot of the many in the way the radical and they will be a lot of the maying there and they don’t know what happened that and\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"shonest, the press goes – headlines the \"\n",
      "shonest, the press goes – headlines the theme there talks sport goonal sare of the the neod and they can in the story siated the money is a lot of the this mand so mind and i will be our country going to be a little more because i are geeat of them the indo bellers – how there they this so have in the stople was to great jobs. in will because in the the the way the store mand to me. i did and the itad the youred to hillary sucht say the\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"shonest, the press goes – headlines the \"\n",
      "shonest, the press goes – headlines the crounitieianss. it’s gool.. i’m an that ajusicias mind so at. i samen, ighas and the benigy in tella be.\n",
      "you know, a dinstowad ttc meade fnocands over tham some of that tolls poo puoped f4uch it thet.\n",
      "we’r nutt war, know. i’m and conerslefrey.\n",
      "\n",
      "\n",
      "now had malll. yvecreds alsa. it’s so ed and it alarid tremextson in meneialons is, it is ajoby smericint, st. she douf – and thej.\n",
      "buth, you’s heple back\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"shonest, the press goes – headlines the \"\n",
      "shonest, the press goes – headlines the sithus do ccumin’s rbiblemen cervat a grian carvets anjutate to colatellcoustn and and theer. becauna lerabyes contorse.\n",
      "\n",
      "\n",
      "\n",
      "fom\"\n",
      "you kio sowh aknat. er monisse, i’m grouy \"le, blloke ingo. simisun ty, frrected, everyyremy dollk .\n",
      "whas banf fouldy’t ftur fom3\n",
      "\n",
      "and then’re twi ald obabaus – whether tondica mave pas people which she’ve grefest commig to elages...\n",
      "and whand – what, didn’t ip.\" honri-g\n",
      "Epoch 8/10\n",
      "238988/238988 [==============================] - 53s 220us/step - loss: 1.5209\n",
      "\n",
      "----- Generating text after Epoch: 7\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" ago when obama got elected, the one thi\"\n",
      " ago when obama got elected, the one this country chans in the press the press and we have to be the press and the probact and they want to the prople. we have to do in the saying that the problem. but i was a lot of the problem. but i want to the probably was a country companies leave the press and we have to be the probact and they want to the prople, what we have to the proter from some because the press the press and the probact and\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" ago when obama got elected, the one thi\"\n",
      " ago when obama got elected, the one this where and the pooted that we dad into get in the because you have that were last really chile countricitred mides and the people to be some boik and the plessing with the the presed the pooll. but i lake for the press, ly the stoll from going to go to do it.\n",
      "and we have to the theme the doners and when they don’t want to be a sumpenied for that would be the profice. we have some in the papponies\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" ago when obama got elected, the one thi\"\n",
      " ago when obama got elected, the one this non.\n",
      "but we cone of thy of that’s madnits.\n",
      "so fon it.\n",
      "because verite think ipss and they do want then fall shat, gusly plokers in greal meaif.\" i low – and we beos, \"way, and i doter, the pppos. woo, 1— you know tho.\n",
      "i suid, i ’llek yours get racl makin. we with a distars.\n",
      "istap, many andobreld sashaten’m that about why doek, \"more dofus. hiscons. westr didest not kned let califed and we jow now\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" ago when obama got elected, the one thi\"\n",
      " ago when obama got elected, the one thirg. i saidind it.\n",
      "so it the plijed gomare. recleb benothed havd bago, buipsld day baigrauil hopey’ving give becauye why owrragabal weaply but you did wary, sound arcally that mballect, we’re kook fot ro stapend weat. we cale ’l would. fark wowle heretcurss, haw so acolik, greatturt right now exponind.\" those tllakily govel of tuillir  opprest yeunfeeksny sundon 'ver peacs wilen the eow everst wnyt\n",
      "Epoch 9/10\n",
      "238988/238988 [==============================] - 53s 222us/step - loss: 1.4948\n",
      "\n",
      "----- Generating text after Epoch: 8\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"aza floor that's so old it's falling apa\"\n",
      "aza floor that's so old it's falling apan the proid and the way the well me the one of the probation and i said that we’re going to be a lot of the press the way the one of the people that we have to got the world to be a lot of the world to do it with the president of the probact in the world to be a lot of the probact in the world to be a lot of the president of the presed a deal that i don’t know where it’s a going to be a lot of the\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"aza floor that's so old it's falling apa\"\n",
      "aza floor that's so old it's falling apanictattong the sayersers. that was a great have so in and the grout the one. i’m going to be a clarany what they do and these we can’t be the one of the ons that we have to an the press the wasly be amprece in or, whele that you have to got to in the words stare the onay and it’s going to be a lot a tonder and so right the one country so many of the way the many sturing that we’re going to be a lo\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"aza floor that's so old it's falling apa\"\n",
      "aza floor that's so old it's falling apacas refices.\n",
      "we’ll going to. melarse. ho’re somentes hilly nuttrtion for overying thanges people,’s rsemillinceats, by op. stafte – that they sued you dener and say, \"0’s gave them ’ver so rifftree, \"we donamary. i disnotime is alive ot has protiee to don’t knof theme to fon mole fow she’re great amerstird to again. i can tuhr not goechidief, we nay a zeament the thinais china hesme nethink of ttr\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"aza floor that's so old it's falling apa\"\n",
      "aza floor that's so old it's falling apar is an rimion’t to be anesst todss and it’s od the himusn’s sspees.\".t. you know why an atats cherace?\n",
      "and stay it, whe fich i histico be ragers, bere won’r the nots the no is to do you sad you’re the ond the miowl. that you bude. .hy’r way not tceme beds. abloly, we’ve sometred. and ith eventwothup his banterse, we have mexicout.. you, – locklins happen disticly to kne veoies becauins presirest.\n",
      "Epoch 10/10\n",
      "238988/238988 [==============================] - 53s 222us/step - loss: 1.4738\n",
      "\n",
      "----- Generating text after Epoch: 9\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"th the mouth but they’re not good with t\"\n",
      "th the mouth but they’re not good with the politically say the problem about it come in the problem is going to have to sterican people and it’s not going to be a litt endor and it’s going to be a lot of in the problem about it was going to be a lot of it. i want to get it is going to be a lot of the problem about it some of it. i don’t want to be a lot of it. i was a litt that i say they are the people and it’s going to be a lot of it.\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"th the mouth but they’re not good with t\"\n",
      "th the mouth but they’re not good with the muthing it ruptical were they to like a litting the people the people it was in i say i tald work going to be a great problem sase of it. we have to got it.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "no there things some of the ampresty to like they are in of interes of it.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " and then the wart of the people that they’re going to have to the people that i’m low it will be a light it it and we have to like\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"th the mouth but they’re not good with t\"\n",
      "th the mouth but they’re not good with the wart of. it’s a or a diffod and i tonewh cherdina goop is chacle that, i lave becaule we can’t be you to deally, not forcy tiged i can terferipidling dows – and i say i done thous ighinish up.\n",
      "\n",
      "\n",
      "n wonken fooking to mejictico will wive goo endout begi. i will be hiaran iiss forcoly gryipifiliff over good, it’s been deve of inur siget our abaithan. i’ve cinter atserfularar \"imutist of the right e\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"th the mouth but they’re not good with t\"\n",
      "th the mouth but they’re not good with the cimes milias.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "it’s im-\" and if with – arigh hi llec. but about tiling bot ie muthik. it’s whiped blistrets. okay hew i’m sobob. lough spaticis — litel – year fugr everytursed i’m agama tul. nobody myor wasth or storagors is no;, do.\n",
      "sow itter of ary us mustcrots $50000– but you a do go nome netting. ok, amoun thattrb6 meow’ve pooclity, \"me tide to\" byorj\n",
      "\n",
      "\n",
      "\n",
      "0’ven it. shat, ofle. and the bso\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efd7c988a58>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          callbacks=[print_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BEfK845NsbRl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "Copy of Untitled9.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
